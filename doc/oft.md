Motivation
==========
Sometimes it can be very informative to extract the *most oft seen* items from
one or more columns of a very large, possibly compressed on storage input stream
- essentially an incomplete histogram.  These could be time-stamp stripped log
messages from a long list of errors or warnings, trending posts on some social
media site (sometimes called "heavy hitters"), or any other situation where a
huge fraction of activity is dominated by a few hundred or thousand popular
items.  (Often this shows up in anything with [Zipfian distributions](zipf.md)).

Count-Min Sketch Method
=======================
Full hash table based histograms can require a great deal of memory.  If you can
be sure your deployment has enough, uncontended low latency DIMM memory to
support the full histogram operation, those are usually still the fastest way.
An only slightly slower way taking dramatically less space is the [Count-Min
Sketch](https://en.wikipedia.org/wiki/Count%E2%80%93min_sketch) which is what
`oft` uses via the `adix/amoft` (approximately most oft) module.

Usage
=====
```
  oft [optional-params] [specs: string...]

Write most often seen N keys in various columns to outFile's.  Specs are
<n>[,<keyCol>(0)[,outFile(stdout)]].  ColNos are Py-like 0-origin,signed.
Algorithm is approximate fast one-pass over mmap|stream input.  E.g., to write
most frequent final column to stdout do: oft 10,-1. (For exact, see lfreq,
possibly with column splitting to FIFOs).

  -i=, --input=  string "/dev/stdin" input data path
  -d=, --delim=  string " "          delimiting (repeats=>any num; "white")
  -m=, --mxCol=  int    0            max columns in input to parse
  -e=, --errate= float  0.005        size tables to make err nSamp*this
  -c=, --cover=  float  0.98         enough tables to make coverage this
  -s=, --salts=  ints   {}           override random salts
```

An Example
==========
A classic example along these lines is word histogramming a la Knuth McIlroy
{ whose good-natured, but competitive framework has spawned many follow-on
[caffeine-fuled rage optimization](https://github.com/benhoyt/countwords)
[comparisons](https://stackoverflow.com/questions/25957835/wordcount-how-inefficient-is-mcilroys-solution)
even though Knuth [was clearly "set
up"](https://buttondown.email/hillelwayne/archive/donald-knuth-was-framed/) }.
Someone should actually do a meta-page linking to the many solutions and various
competitions.  (Well, someone probably has..Feel free to PR a link.)

```sh
$ curl https://www.gutenberg.org/files/98/98-0.txt > to2c.txt
$ tr A-Z a-z < to2c.txt | tr -sc a-z \\n >/dev/shm/j; ru oft 10 </dev/shm/j
1957 that
1990 i
2011 his
2082 it
2664 in
3016 a
3653 to
4142 of
5067 and
8242 the
$ lfreq -n10 -d98304 < to2c.wrd # from adix/util
1956 that
1990 i
2011 his
2082 it
2664 in
3016 a
3653 to
4142 of
5067 and
8242 the
```
Notice how the results are nearly the same - only an over-count by 1 on the 10th
most seen word, "that".  Such over-counting is the only way this particular
approximation fails.  (There are optional parameters to fiddle with accuracy of
the count-min sketch.)

It is a bit slower if you don't really need all the memory savings, though:
```
$ tim 'lfreq -n10 -d98304 <to2c.wrd>/dev/null' 'oft 10 <to2c.wrd>/dev/null'
(6.189 +- 0.019)e-03    lfreq -n10 -d98304 <to2c.wrd>/dev/null
0.014735 +- 0.000012    oft 10 <to2c.wrd>/dev/null
```

So, about ~2.4x slower with the default accuracy settings.  Sometimes a "cache
cliff" { a large move in a latency diagram as generated by [memlat](memlat.md) }
can be >>2.4x, though.  E.g., it is often 8X from CPU to DIMMs.  In this case,
that might mean the problem was about larger vocabularies than Dickens uses in
that one book.  So, this could be an interesting data structure even in settings
that do not exhaust DIMM memory.  Another example might be fitting in private
L2 CPU cache in a parallelization setting since the shared L3 cache faces more
contention amongst procs/threads.
